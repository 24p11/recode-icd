{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP6qe01bmWO5TxCHR4vVOgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24p11/recode-icd/blob/main/final_finetuning_different_backbone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gliner==0.2.21\n",
        "# !pip install accelerate -U\n",
        "# !pip install transformers==4.48.0"
      ],
      "metadata": {
        "id": "y5DJXkP4I3F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = \"xxx\""
      ],
      "metadata": {
        "id": "ci7gP_1u6YPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czzJ-oXEDP7z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "import argparse\n",
        "import random\n",
        "random.seed(42)\n",
        "import json\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "from gliner import GLiNERConfig, GLiNER\n",
        "from gliner.training import Trainer, TrainingArguments\n",
        "from gliner.data_processing.collator import DataCollatorWithPadding, DataCollator\n",
        "from gliner.utils import load_config_as_namespace\n",
        "from gliner.data_processing import WordsSplitter, GLiNERDataset\n",
        "\n",
        "from transformers import TrainerCallback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class MetricCollector(TrainerCallback):\n",
        "#     def __init__(self):\n",
        "#         self.train_losses = []\n",
        "#         self.grad_norms = []\n",
        "#         self.eval_losses = []\n",
        "\n",
        "#     def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "#         if logs:\n",
        "#             if \"loss\" in logs:\n",
        "#                 self.train_losses.append((state.global_step, float(logs[\"loss\"])))\n",
        "#             if \"grad_norm\" in logs:\n",
        "#                 self.grad_norms.append((state.global_step, float(logs[\"grad_norm\"])))\n",
        "\n",
        "#     def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "#         if metrics is not None:\n",
        "#             if \"eval_loss\" in metrics:\n",
        "#                 self.eval_losses.append(metrics[\"eval_loss\"])"
      ],
      "metadata": {
        "id": "Wx1D7-jwI7l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/Scenario/modern_data_1000_ner.json\"\n",
        "\n",
        "print (\"Loading data...\")\n",
        "with open(data_path, 'r', encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "print (\"Data loaded!!!\")\n",
        "\n",
        "print('Dataset size:', len(data))\n",
        "print (\"Shuffling data...\")\n",
        "random.shuffle(data)\n",
        "print (\"Data shuffled!!!\")\n",
        "\n",
        "print (\"Dividing data...\")\n",
        "train_data = data[:int(len(data)*0.9)]\n",
        "dev_data = data[int(len(data)*0.9):]\n",
        "print (\"Data divided!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zokffrReJClc",
        "outputId": "1fc1064c-0c90-462f-fa88-82afb5953ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading data...\n",
            "Data loaded!!!\n",
            "Dataset size: 995\n",
            "Shuffling data...\n",
            "Data shuffled!!!\n",
            "Dividing data...\n",
            "Data divided!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = load_config_as_namespace(\"config-different-backbone.yaml\")\n",
        "config.log_dir = \"gliner_modernbert/\"\n",
        "# config.num_steps = 4\n",
        "# config.train_batch_size = 4\n",
        "# config.eval_every = 2\n",
        "config.output_dir = config.log_dir+f\"lossgamma{config.loss_gamma}_lrencoder{config.lr_encoder}_lrothers{config.lr_others}\"\n",
        "\n",
        "model_config = GLiNERConfig(**vars(config))\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_config.model_name, add_prefix_space=True)\n",
        "words_splitter = WordsSplitter(model_config.words_splitter_type)\n",
        "model = GLiNER(model_config, tokenizer=tokenizer, words_splitter=words_splitter)\n",
        "\n",
        "\n",
        "model_config.class_token_index=len(tokenizer)\n",
        "tokenizer.add_tokens([model_config.ent_token, model_config.sep_token], special_tokens=True)\n",
        "model_config.vocab_size = len(tokenizer)\n",
        "model.resize_token_embeddings([model_config.ent_token, model_config.sep_token],\n",
        "                              set_class_token_index=False,\n",
        "                              add_tokens_to_tokenizer=False)\n",
        "\n",
        "model.model.token_rep_layer.bert_layer.model.requires_grad_(True)\n",
        "\n",
        "data_collator = DataCollator(model.config, data_processor=model.data_processor, prepare_labels=True)"
      ],
      "metadata": {
        "id": "Rgkb2e5SJPNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "        output_dir=config.output_dir,\n",
        "        learning_rate=float(config.lr_encoder),\n",
        "        weight_decay=float(config.weight_decay_encoder),\n",
        "        others_lr=float(config.lr_others),\n",
        "        others_weight_decay=float(config.weight_decay_others),\n",
        "        focal_loss_gamma=float(config.loss_gamma),\n",
        "        focal_loss_alpha=float(config.loss_alpha),\n",
        "        loss_reduction=config.loss_reduction,\n",
        "        lr_scheduler_type=config.scheduler_type,\n",
        "        warmup_ratio=config.warmup_ratio,\n",
        "        per_device_train_batch_size=config.train_batch_size,\n",
        "        per_device_eval_batch_size=config.train_batch_size*2,\n",
        "        max_grad_norm=config.max_grad_norm,\n",
        "        max_steps=config.num_steps,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=config.eval_every,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps = config.eval_every,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=100,\n",
        "        # logging_steps=1,\n",
        "        save_total_limit=config.save_total_limit,\n",
        "        dataloader_num_workers=0,\n",
        "        use_cpu=False,\n",
        "        report_to=\"tensorboard\",\n",
        "        seed=42,\n",
        "        eval_do_concat_batches=True,\n",
        "        eval_on_start=True,\n",
        "        save_only_model=True\n",
        "        )\n",
        "\n",
        "# collector = MetricCollector()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=dev_data,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    # callbacks=[collector],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR4A5z6cJzvG",
        "outputId": "ff133d1e-670a-470e-d855-205bb3bf11ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-783904213.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Training...\")\n",
        "trainer.train()\n",
        "print (\"Done training!!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "Vp8J5y3LJ6yG",
        "outputId": "842d5d3a-e76a-41d7-ae9e-611dcbec33cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12009' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12009/20000 19:36:58 < 13:03:18, 0.17 it/s, Epoch 53.61/90]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>11686057.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>352.206800</td>\n",
              "      <td>1035.311646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>89.007600</td>\n",
              "      <td>2783.840820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>30.985600</td>\n",
              "      <td>4544.872070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gliner/data_processing/collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         model_input.update({\"span_idx\": raw_batch['span_idx'] if 'span_idx' in raw_batch else None, \n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gliner/data_processing/processor.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, batch, prepare_labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mmodel_input_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize_and_prepare_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_input_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gliner/data_processing/processor.py\u001b[0m in \u001b[0;36mtokenize_and_prepare_labels\u001b[0;34m(self, batch, prepare_labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprepare_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0mtokenized_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gliner/data_processing/processor.py\u001b[0m in \u001b[0;36mcreate_labels\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    346\u001b[0m             span_to_index = {\n\u001b[0;32m--> 347\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mspans_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspans_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1458930375.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Done training!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2478\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m                     \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5156\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5157\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5158\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks_on_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf gliner_modernbert"
      ],
      "metadata": {
        "id": "Gy47nnQ9TC0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{config.output_dir}/metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(\n",
        "          {\n",
        "              \"train_losses\": collector.train_losses,\n",
        "              \"grad_norms\": collector.grad_norms,\n",
        "              \"eval_losses\": collector.eval_losses,\n",
        "          },\n",
        "          f\n",
        "      )"
      ],
      "metadata": {
        "id": "Y6tev2UDJ9Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r gliner_modernbert.zip gliner_modernbert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRLvDJ21USBR",
        "outputId": "d40df052-0969-444a-d6e5-94e8c9767676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: gliner_modernbert/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/metrics.json (deflated 61%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/tokenizer.json (deflated 82%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/tokenizer_config.json (deflated 95%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/gliner_config.json (deflated 64%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/special_tokens_map.json (deflated 79%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/pytorch_model.bin (deflated 7%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-8000/trainer_state.json (deflated 79%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/tokenizer.json (deflated 82%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/tokenizer_config.json (deflated 95%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/gliner_config.json (deflated 64%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/special_tokens_map.json (deflated 79%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/pytorch_model.bin (deflated 7%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-4000/trainer_state.json (deflated 77%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/runs/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/runs/Sep24_15-59-55_a7a7575ed651/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/runs/Sep24_15-59-55_a7a7575ed651/events.out.tfevents.1758729601.a7a7575ed651.5944.14 (deflated 68%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/ (stored 0%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/tokenizer.json (deflated 82%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/tokenizer_config.json (deflated 95%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/gliner_config.json (deflated 64%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/special_tokens_map.json (deflated 79%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/pytorch_model.bin (deflated 7%)\n",
            "  adding: gliner_modernbert/lossgamma0.0_lrencoder1e-5_lrothers5e-5/checkpoint-12000/trainer_state.json (deflated 79%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, login\n",
        "\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"gliner_modernbert.zip\",\n",
        "    path_in_repo=\"gliner_modernbert.zip\",\n",
        "    repo_id=\"anhthuw01/gliner_onco\",\n",
        "    repo_type=\"model\"\n",
        ")"
      ],
      "metadata": {
        "id": "VfQhhpoaVBTf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}